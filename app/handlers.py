from aiogram import F, Router
from aiogram.types import Message
from aiogram.filters import CommandStart
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext
from loguru import logger
import time

from app.generators import gpt
from logger import file_logger
from app import cmd_message
from app.count_token import count_tokens
import app.keyboards as kb
from app.split_text import split_text
from .database.db import clear_message_history
from app.call_count_gpt import count_calls


router = Router()

# –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
last_message_time = {}


class Generate(StatesGroup):
    selecting_model = State()           # –°–æ—Å—Ç–æ—è–Ω–∏–µ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
    text_input = State()                # –°–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    waiting_for_response = State()      # –û–∂–∏–¥–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ gpt


@logger.catch
@router.message(CommandStart())
async def cmd_start(message: Message, state: FSMContext):

    file_logger()

    try:
        await message.answer(cmd_message.start_message, reply_markup=kb.main)
        await state.clear()  # –û—á–∏—Å—Ç–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        await state.set_state(Generate.selecting_model)  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
    except Exception as err:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–≤–æ–¥–µ –∫–æ–º–∞–Ω–¥—ã /start: {err}")
        await message.answer(cmd_message.error_message)


@logger.catch
@router.message(F.text == "–ü–æ–º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å gpt")
async def change_gpt_model(message: Message, state: FSMContext):
    file_logger()
    try:
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å gpt:", reply_markup=kb.main)
        await state.set_state(Generate.selecting_model)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–∏
    except Exception as err:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–º–µ–Ω–µ –º–æ–¥–µ–ª–∏ gpt: {err}")
        await message.answer(cmd_message.error_message)


@logger.catch
@router.message(F.text == "–°–±—Ä–æ—Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
async def reset_context(message: Message, state: FSMContext):
    file_logger()
    telegram_id = message.from_user.id
    try:
        # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        await clear_message_history(telegram_id)
        await message.reply(cmd_message.reset_context_message)
    except Exception as err:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±—Ä–æ—Å–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {err}")
        await message.answer(cmd_message.error_message)


@logger.catch
@router.message(F.text == "‚ùå–ú–æ–¥–µ–ª—å 4-o‚ùå")
async def non_gpt_4o(message: Message, state: FSMContext):
    file_logger()
    await message.reply(f"–ú–æ–¥–µ–ª—å gpt-4o –≤ —Ä–µ–∂–∏–º–µ –∞–ª—å—Ñ–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –¥–æ—Å—Ç—É–ø–Ω–∞ —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª—å gpt-4o-mini")
    return


@logger.catch
@router.message(F.text.in_(["‚ùå–ú–æ–¥–µ–ª—å 4-o‚ùå", "‚úÖ–ú–æ–¥–µ–ª—å 4-o-mini‚úÖ"]))
async def select_model(message: Message, state: FSMContext):
    file_logger()
    model_mapping = {
        "‚ùå–ú–æ–¥–µ–ª—å 4-o‚ùå": "gpt-4o",
        "‚úÖ–ú–æ–¥–µ–ª—å 4-o-mini‚úÖ": "gpt-4o-mini"
    }
    model = model_mapping.get(message.text)
    
    await state.update_data(model=model)
    await state.set_state(Generate.text_input)

    await message.answer(f"–í—ã –≤—ã–±—Ä–∞–ª–∏ {model}. –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:", reply_markup=await kb.change_model(model))


@logger.catch
@router.message(Generate.text_input)
@count_calls()
async def process_generation(message: Message, state: FSMContext):
    file_logger()

    telegram_id = message.from_user.id
    current_time = time.time()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    if telegram_id in last_message_time and current_time - last_message_time[telegram_id] < 1:
        # –ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –º–µ–Ω—å—à–µ 0.5 —Å–µ–∫—É–Ω–¥, –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        return

    last_message_time[telegram_id] = current_time

    # # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–ø–∏—Å–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    # if telegram_id not in [2050793273, 857805093]:
    #     await message.answer("–ò–∑–≤–∏–Ω–∏—Ç–µ, –≤–∞–º –æ—Ç–∫–∞–∑–∞–Ω–æ –≤ –¥–æ—Å—Ç—É–ø–µ, —Å–∫–æ—Ä–æ –±–æ—Ç –≤—ã–π–¥–µ—Ç –≤ –æ–±—â–µ–µ –ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ!")
    #     return

    data = await state.get_data()
    model = data.get("model")
    user_input = message.text

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É —Å–æ–æ–±—â–µ–Ω–∏—è
    if len(user_input) >= 4096:
        await message.answer("–°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–æ–∫—Ä–∞—Ç–∏—Ç–µ –µ–≥–æ –¥–ª–∏–Ω—É –¥–æ 4096 —Å–∏–º–≤–æ–ª–æ–≤.")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
        await state.set_state(Generate.text_input)
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    current_state = await state.get_state()

    if current_state == Generate.waiting_for_response.state:
        await message.reply("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.")
        return

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è
    await state.set_state(Generate.waiting_for_response)

    await message.reply(f"‚ú® –ú–æ–¥–µ–ª—å: {model}. –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è: –≤—Å–µ–≥–æ 5-19 —Å–µ–∫—É–Ω–¥! ‚è±üöÄ\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ‚ú®")

    try:
        response = await gpt(user_input, model, telegram_id)
    except Exception as err:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ gpt: {err}")
        await message.answer(cmd_message.error_message)
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
        await state.set_state(Generate.text_input)
        return

    try:
        # –†–∞–∑–¥–µ–ª—è–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ 4096 —Å–∏–º–≤–æ–ª–æ–≤
        response_parts = split_text(response)
        for part in response_parts:
            await message.reply(
                f"–í–∞—à –æ—Ç–≤–µ—Ç, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —Å –ø–æ–º–æ—â—å—é {model}:\n\n{part}\n\n–ö–æ–ª-–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ input: {count_tokens(user_input)}\n–ö–æ–ª-–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ output: {count_tokens(part)}", 
                parse_mode="Markdown",
                reply_markup=await kb.change_model(model)  # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–º–µ–Ω—ã –º–æ–¥–µ–ª–∏
            )
        logger.info("–û—Ç–≤–µ—Ç gpt –ø–æ–ª—É—á–µ–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
        await state.set_state(Generate.text_input)
    except Exception as err:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {err}")
        await message.reply(cmd_message.error_message)
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞
        await state.set_state(Generate.text_input)
        return


@logger.catch
@router.message(F.text)
async def error_handling(message: Message, state: FSMContext):
    current_state = await state.get_state()

    if current_state == Generate.waiting_for_response.state:
        await message.reply("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.")
    elif current_state == Generate.text_input.state:
        await process_generation(message, state)
    else:
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å gpt", reply_markup=kb.main)
